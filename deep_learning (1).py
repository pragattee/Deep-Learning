# -*- coding: utf-8 -*-
"""Deep Learning.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1bARswngOujnS5P_WcNwn2V00-ZLKofP4
"""

from google.colab import files

# This will prompt you to select files to upload
uploaded = files.upload()

import os
os.listdir()

import numpy as np
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
import os
from tensorflow.keras.preprocessing.image import ImageDataGenerator

# Define paths
train_dir = 'cifar-10/train'  # Adjust based on your extracted structure
test_dir = 'cifar-10/test'

# Data preprocessing using ImageDataGenerator
datagen = ImageDataGenerator(rescale=1.0/255.0)

!pip install tensorflow --upgrade

import numpy as np
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
from tensorflow.keras.datasets import cifar10
from tensorflow.keras.utils import to_categorical

# Step 2: Load the CIFAR-10 dataset
(x_train, y_train), (x_test, y_test) = cifar10.load_data()

# Step 3: Preprocess the data
# Normalize the pixel values to be between 0 and 1
x_train = x_train.astype('float32') / 255.0
x_test = x_test.astype('float32') / 255.0

# One-hot encode the labels
y_train = to_categorical(y_train, num_classes=10)
y_test = to_categorical(y_test, num_classes=10)

# Step 4: Build the CNN model
model = Sequential([
    Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),
    MaxPooling2D(pool_size=(2, 2)),
    Conv2D(64, (3, 3), activation='relu'),
    MaxPooling2D(pool_size=(2, 2)),
    Conv2D(128, (3, 3), activation='relu'),
    MaxPooling2D(pool_size=(2, 2)),
    Flatten(),
    Dense(128, activation='relu'),
    Dropout(0.5),
    Dense(10, activation='softmax')  # 10 classes
])

# Step 5: Compile the model
model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

# Step 6: Train the model
model.fit(x_train, y_train, epochs=10, batch_size=64, validation_split=0.2)

# Step 7: Evaluate the model
test_loss, test_accuracy = model.evaluate(x_test, y_test)
train_loss, train_accuracy = model.evaluate(x_train, y_train)
# Convert accuracy to percentage
test_accuracy_percentage = test_accuracy * 100
train_accuracy_percentage = train_accuracy * 100
# Print the train accuracy in percentage
print(f'Train accuracy: {train_accuracy_percentage:.2f}%')
print(f'Test accuracy: {test_accuracy_percentage:.2f}%')

history = model.fit(
    x_train, y_train,
    epochs=10,
    batch_size=64,
    validation_split=0.2
)

import matplotlib.pyplot as plt

# Ensure 'history' contains data from model.fit
plt.figure(figsize=(12, 5))

# Plot training & validation accuracy
plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.title('Model Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend(loc='lower right')

# Annotate final train and test accuracy
plt.annotate(f'Train Accuracy: {train_accuracy_percentage:.2f}%',
             xy=(len(history.history['accuracy']) - 1, history.history['accuracy'][-1]),
             xytext=(len(history.history['accuracy']) - 1, history.history['accuracy'][-1] + 0.05),
             ha='center', color='blue')
plt.annotate(f'Test Accuracy: {test_accuracy_percentage:.2f}%',
             xy=(len(history.history['val_accuracy']) - 1, history.history['val_accuracy'][-1]),
             xytext=(len(history.history['val_accuracy']) - 1, history.history['val_accuracy'][-1] + 0.05),
             ha='center', color='orange')

# Plot training & validation loss
plt.subplot(1, 2, 2)
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('Model Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend(loc='upper right')

plt.tight_layout()
plt.show()

import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix
from tensorflow.keras.datasets import cifar10

# Load CIFAR-10 dataset
(_, _), (x_test, y_test) = cifar10.load_data()

# Normalize pixel values to be between 0 and 1
x_test = x_test.astype('float32') / 255.0

# Get class labels
y_test_classes = y_test.flatten()

# Make predictions
y_pred = model.predict(x_test)
y_pred_classes = np.argmax(y_pred, axis=1)

# Generate confusion matrix
cm = confusion_matrix(y_test_classes, y_pred_classes)

# Define class names for CIFAR-10
class_names = [
    'Airplane', 'Automobile', 'Bird', 'Cat', 'Deer',
    'Dog', 'Frog', 'Horse', 'Ship', 'Truck'
]

# Plotting the confusion matrix
plt.figure(figsize=(10, 8))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Confusion Matrix')
plt.show()